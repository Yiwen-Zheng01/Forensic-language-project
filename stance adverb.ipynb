{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c65b1a-d3a6-4688-aac3-63766291b4be",
   "metadata": {},
   "source": [
    "Calculate the amount of words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c7e9d4-a17a-429c-becb-4210b13220b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yiwen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to D:\\Judicial_corpus\\yearly_word_counts_and_std.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure the NLTK tokenizer is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "def calculate_folder_word_count_and_std(base_path):\n",
    "    stats = []\n",
    "\n",
    "    # Iterate over each subfolder in the base directory\n",
    "    for folder in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            word_counts = []\n",
    "            \n",
    "            # Process each file within the subfolder\n",
    "            for filename in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        text = file.read()\n",
    "                        tokens = word_tokenize(text)\n",
    "                        word_counts.append(len(tokens))\n",
    "            \n",
    "            if word_counts:\n",
    "                # Calculate total word count and standard deviation for the current folder\n",
    "                total_words = sum(word_counts)\n",
    "                std_dev = pd.Series(word_counts).std()\n",
    "                stats.append({'Year': folder, 'Total Word Count': total_words, 'Standard Deviation': std_dev})\n",
    "\n",
    "    return stats\n",
    "\n",
    "def main():\n",
    "    base_path = r\"D:\\Judicial_corpus\"  \n",
    "    results = calculate_folder_word_count_and_std(base_path)\n",
    "    \n",
    "    if results:\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        # Save to CSV\n",
    "        csv_path = os.path.join(base_path, 'yearly_word_counts_and_std.csv')\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Data saved to {csv_path}\")\n",
    "    else:\n",
    "        print(\"No subfolders found or no word counts to process.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c9c1f-ae05-4931-8f0d-698d33ba1df3",
   "metadata": {},
   "source": [
    "Search for attitudinal adverb and calculate the raw and normalized frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37162136-6fa6-4d7f-880a-1f2b7b4c700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2006...\n",
      "Processing 2007...\n",
      "Processing 2008...\n",
      "Processing 2009...\n",
      "Processing 2010...\n",
      "Processing 2011...\n",
      "Processing 2012...\n",
      "Processing 2013...\n",
      "Processing 2014...\n",
      "Processing 2015...\n",
      "Processing 2016...\n",
      "Processing 2017...\n",
      "Processing 2018...\n",
      "Processing 2019...\n",
      "Processing 2020...\n",
      "Processing 2021...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# List of adverbs to search\n",
    "adverbs = [\"appropriately\", \"correctly\", \"fortunately\", \"importantly\", \"improperly\", \"properly\", \"unfortunately\"]\n",
    "\n",
    "def count_words_and_adverbs(text, adverb_list):\n",
    "    word_count = 0\n",
    "    adverb_count = Counter()\n",
    "    words = text.split()\n",
    "    word_count += len(words)\n",
    "    for word in words:\n",
    "        if word.lower() in adverb_list:\n",
    "            adverb_count[word.lower()] += 1\n",
    "    return word_count, adverb_count\n",
    "\n",
    "def process_directory(directory, adverb_list):\n",
    "    total_word_count = 0\n",
    "    total_adverb_counts = Counter()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                word_count, adverb_counts = count_words_and_adverbs(text, adverb_list)\n",
    "                total_word_count += word_count\n",
    "                total_adverb_counts.update(adverb_counts)\n",
    "    return total_word_count, total_adverb_counts\n",
    "\n",
    "def main(base_directory, adverb_list):\n",
    "    results = defaultdict(dict)\n",
    "    # Collect data for each year\n",
    "    for year in sorted(os.listdir(base_directory)):\n",
    "        year_dir = os.path.join(base_directory, year)\n",
    "        if os.path.isdir(year_dir):\n",
    "            print(f\"Processing {year}...\")\n",
    "            word_count, adverb_counts = process_directory(year_dir, adverb_list)\n",
    "            for adverb in adverb_list:\n",
    "                raw_freq = adverb_counts[adverb]\n",
    "                norm_freq = (raw_freq / word_count) * 1_000_000\n",
    "                results[year][f\"{adverb} Raw Frequency\"] = raw_freq\n",
    "                results[year][f\"{adverb} Normalized Frequency\"] = norm_freq\n",
    "    \n",
    "    # Write to a single CSV file\n",
    "    with open(\"adverbs_over_years.csv\", 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Year'] + [f\"{adverb} {metric}\" for adverb in adverb_list for metric in [\"Raw Frequency\", \"Normalized Frequency\"]]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for year in sorted(results):\n",
    "            row = {'Year': year}\n",
    "            row.update(results[year])\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call the function\n",
    "main(r\"D:\\Judicial_corpus\", adverbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b964b-4f0d-495c-970f-9db61ef236f4",
   "metadata": {},
   "source": [
    "Search for stance adverbs of emphasis and calculate hte raw and normalized frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80d72c82-288c-425b-acdb-c6bf429630a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2006...\n",
      "Processing 2007...\n",
      "Processing 2008...\n",
      "Processing 2009...\n",
      "Processing 2010...\n",
      "Processing 2011...\n",
      "Processing 2012...\n",
      "Processing 2013...\n",
      "Processing 2014...\n",
      "Processing 2015...\n",
      "Processing 2016...\n",
      "Processing 2017...\n",
      "Processing 2018...\n",
      "Processing 2019...\n",
      "Processing 2020...\n",
      "Processing 2021...\n"
     ]
    }
   ],
   "source": [
    "# List of adverbs to search\n",
    "adverbs = [\"actually\", \"certainly\", \"clearly\", \"especially\", \"fully\", \n",
    "           \"highly\", \"indeed\", \"merely\", \"particularly\", \"plainly\", \n",
    "           \"precisely\", \"readily\", \"simply\", \"surely\"]\n",
    "\n",
    "def count_words_and_adverbs(text, adverb_list):\n",
    "    word_count = 0\n",
    "    adverb_count = Counter()\n",
    "    words = text.split()\n",
    "    word_count += len(words)\n",
    "    for word in words:\n",
    "        if word.lower() in adverb_list:\n",
    "            adverb_count[word.lower()] += 1\n",
    "    return word_count, adverb_count\n",
    "\n",
    "def process_directory(directory, adverb_list):\n",
    "    total_word_count = 0\n",
    "    total_adverb_counts = Counter()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                word_count, adverb_counts = count_words_and_adverbs(text, adverb_list)\n",
    "                total_word_count += word_count\n",
    "                total_adverb_counts.update(adverb_counts)\n",
    "    return total_word_count, total_adverb_counts\n",
    "\n",
    "def main(base_directory, adverb_list):\n",
    "    results = defaultdict(dict)\n",
    "    # Collect data for each year\n",
    "    for year in sorted(os.listdir(base_directory)):\n",
    "        year_dir = os.path.join(base_directory, year)\n",
    "        if os.path.isdir(year_dir):\n",
    "            print(f\"Processing {year}...\")\n",
    "            word_count, adverb_counts = process_directory(year_dir, adverb_list)\n",
    "            for adverb in adverb_list:\n",
    "                raw_freq = adverb_counts[adverb]\n",
    "                norm_freq = (raw_freq / word_count) * 1_000_000\n",
    "                results[year][f\"{adverb} Raw Frequency\"] = raw_freq\n",
    "                results[year][f\"{adverb} Normalized Frequency\"] = norm_freq\n",
    "    \n",
    "    # Write to a single CSV file\n",
    "    with open(\"emphasis_adverbs_over_years.csv\", 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Year'] + [f\"{adverb} {metric}\" for adverb in adverb_list for metric in [\"Raw Frequency\", \"Normalized Frequency\"]]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for year in sorted(results):\n",
    "            row = {'Year': year}\n",
    "            row.update(results[year])\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call the function\n",
    "main(r\"D:\\Judicial_corpus\", adverbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b07dc12-eb94-4eb0-94fa-d403f9620a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
